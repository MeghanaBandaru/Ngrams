{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of next word of a sentence using Pentagram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Read the corpus file line by line\n",
    "### 2)Preprocess the content of the file:\n",
    "       (i) Lower case all the words\n",
    "       (ii) Remove puntuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053640\n",
      "62705\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "tokens=[]\n",
    "#with open('/home/meghana/new_jupyter/assign1/Data/Tokenization/Chat1.txt') as f:\n",
    "with open('/home/meghana/nltk_data/corpora/gutenberg/corpusfile.txt') as f:\n",
    "\n",
    "    for line in f:\n",
    "        if not line.isspace():\n",
    "            items=line.split()\n",
    "            #print(\"words in list;\",items)\n",
    "            i=0\n",
    "            for w in items:\n",
    "                items[i]=w.lower()\n",
    "                items[i]=items[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace(\"'\",'')                                 \n",
    "                i+=1\n",
    "            tokens+=items\n",
    "tokenSet=set(tokens)\n",
    "print(len(tokens))\n",
    "print(len(tokenSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtered_words=[word for word in tokens if word not in stopwords.words('english')]\n",
    "# #filtered_words_set=set(filtered_words)\n",
    "# print(len(filtered_words))\n",
    "# print(len(filtered_words_set))\n",
    "# tokens=filtered_words\n",
    "# tokenSet=set(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the words of the files as ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1826910\n",
      "1956033\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "unigrams=list(ngrams(tokens,1))\n",
    "quadgrams=list(ngrams(tokens,4))\n",
    "quadgramSet=set(quadgrams)\n",
    "pentagrams=list(ngrams(tokens,5))\n",
    "pentagramSet=set(pentagrams)\n",
    "print(len(quadgramSet))\n",
    "print(len(pentagramSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the probability tables of quadgrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "[('the children of israel', 635), ('it came to pass', 457), ('thus saith the lord', 415), ('and it came to', 396), ('of the children of', 376), ('the lord thy god', 304), ('the house of the', 284), ('the word of the', 271), ('in the midst of', 269), ('word of the lord', 259)]\n",
      "[('and it came to pass', 396), ('the word of the lord', 259), ('the house of the lord', 235), ('of the children of israel', 163), ('thus saith the lord god', 162), ('it came to pass when', 142), ('the tabernacle of the congregation', 133), ('and the lord said unto', 124), ('saith the lord of hosts', 123), ('it shall come to pass', 120)]\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "from collections import Counter\n",
    "\n",
    "unigram_table=Counter(unigrams)\n",
    "default=(unigram_table.most_common(1))\n",
    "default=str(default[0][0])\n",
    "default=default.replace('(','').replace(\"'\",'').replace(',','').replace(')','')\n",
    "print(default)\n",
    "\n",
    "quadgram_list=[]\n",
    "for item in quadgrams:\n",
    "    new_item=' '.join(item)\n",
    "    quadgram_list.append(new_item)\n",
    "\n",
    "quadgram_table=Counter(quadgram_list)   \n",
    "print(quadgram_table.most_common(10))\n",
    "\n",
    "\n",
    "pentagram_list=[]\n",
    "for item in pentagrams:\n",
    "    new_item=' '.join(item)\n",
    "    pentagram_list.append(new_item)\n",
    "\n",
    "pentagram_table=Counter(pentagram_list)   \n",
    "print(pentagram_table.most_common(10))\n",
    "#print(quadgram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Look up the quadgram and trigram tables \n",
    "### 2)Take the input string\n",
    "### 3)Find out the probability and predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a string:I am Meghana Bandaru and I must say\n",
      "The next word is: that\n",
      "Enter a string:I am Meghana Bandaru and I must say\n",
      "The next word is: that\n",
      "Enter a string:I am Meghana Bandaru and I must say\n",
      "The next word is: that\n",
      "Enter a string:I am Meghana Bandaru and I must say\n",
      "The next word is: that\n",
      "The slowest run took 10.43 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 1.89 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#s=\"I am Meghana Bandaru and I must\"\n",
    "s=input(\"Enter a string:\")\n",
    "s_tokens=s.split()\n",
    "#s_filtered_words=[word for word in s_tokens if word not in stopwords.words('english')]\n",
    "#s_tokens=s_filtered_words\n",
    "i=0\n",
    "for w in s_tokens:\n",
    "    s_tokens[i]=w.lower()\n",
    "    s_tokens[i]=s_tokens[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace(\"'\",'')                                 \n",
    "    i+=1\n",
    "\n",
    "s_quadgrams=list(ngrams(s_tokens, 4))\n",
    "#print(s_trigrams)\n",
    "n=len(s_quadgrams)\n",
    "req_quadgram=s_quadgrams[n-1]\n",
    "req_quadgram=' '.join(req_quadgram)\n",
    "#print(req_trigram)\n",
    "\n",
    "prob=0\n",
    "freq_tri=0\n",
    "freq_quad=0\n",
    "max_prob=0\n",
    "result=0\n",
    "word=0\n",
    "for item in tokenSet:\n",
    "    new_req_quadgram=req_quadgram+' '+item\n",
    "    freq_penta=pentagram_table[new_req_quadgram]\n",
    "    freq_quad=quadgram_table[req_quadgram]\n",
    "    if(freq_quad==0):\n",
    "        break\n",
    "    prob=freq_penta/freq_quad\n",
    "    if(prob>max_prob):\n",
    "        max_prob=prob\n",
    "        result=new_req_quadgram\n",
    "        word=item\n",
    "if(word==0):\n",
    "    word=default\n",
    "    result=req_trigram+' '+str(default)\n",
    "    \n",
    "print(\"The next word is:\", word)\n",
    "#print(\"The sentence might be:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
