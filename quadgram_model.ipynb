{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadgram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess=lambda line: line.replace('.',' ').replace(',',' ').replace(':',' ').replace(';',' ').replace('!',' ').replace('?',' ').replace('(',' ').replace(')',' ').replace(\"-\",\" \").replace(\" '\",' ').replace(\"' \",' ').replace('\"',' ').replace(\"_\",\" \").replace('[',' ').replace(']',\" \").replace('{',' ').replace('}',\" \").replace('*',' ')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to preprocess the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTokens(file):\n",
    "    tokens=[]\n",
    "    #with open('/home/meghana/nltk_data/corpora/gutenberg/training_corpus.txt') as f:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if not line.isspace():\n",
    "                line=line.lower()\n",
    "                line=preprocess(line)\n",
    "            items=line.split()\n",
    "            tokens+=items\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_perplexity(prob_table,test_quads,n):\n",
    "    pp=1.0\n",
    "    for quad in test_quads:\n",
    "        try:\n",
    "            pp=pp*((1/float(prob_table[quad[0:3]][quad[3]]))**(1/n))\n",
    "        except:\n",
    "            pass\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 sets of data.\n",
    "+ Train set\n",
    "+ Test set\n",
    "+ Held set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Train   Test   Held-out\n",
      "Total  1889452 104950 105479\n",
      "Unique   41617 11188   11253\n"
     ]
    }
   ],
   "source": [
    "train_tokens=getTokens('training.txt')\n",
    "test_tokens=getTokens('test_set.txt')\n",
    "held_tokens=getTokens('held_set.txt')\n",
    "print(\"        Train   Test   Held-out\")\n",
    "print(\"Total \",len(train_tokens),len(test_tokens),len(held_tokens))\n",
    "train_tokenSet=set(train_tokens)\n",
    "test_tokenSet=set(test_tokens)\n",
    "held_tokenSet=set(held_tokens)\n",
    "print(\"Unique  \",len(train_tokenSet),len(test_tokenSet),\" \",len(held_tokenSet))\n",
    "# 1891868 103419 104594\n",
    "# 35487 12831 11647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "unigrams=list(ngrams(train_tokens,1))\n",
    "bigrams=list(ngrams(train_tokens,2))\n",
    "trigrams=list(ngrams(train_tokens,3))\n",
    "quadgrams=list(ngrams(train_tokens,4))\n",
    "V=len(set(quadgrams))\n",
    "\n",
    "held_quadgrams=list(ngrams(held_tokens,4))\n",
    "held_quadgramSet=set(held_quadgrams)\n",
    "\n",
    "test_quadgrams=list(ngrams(test_tokens,4))\n",
    "test_quadgramSet=set(test_quadgrams)\n",
    "\n",
    "unigram_table=Counter(train_tokens)\n",
    "bigram_table=Counter(bigrams)#stores the frequencies of each bigram similarly trigrams and quadgrams\n",
    "trigram_table=Counter(trigrams)\n",
    "quadgram_table=Counter(quadgrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Probabiity table:\n",
    "+ The data structure used is defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in quadgram_table:\n",
    "    tri=key[0:3]\n",
    "    quadgram_table[key]=((quadgram_table[key])/(trigram_table[tri]))\n",
    "                         \n",
    "quad_prob_table=defaultdict(dict)\n",
    "\n",
    "for quad in quadgram_table:\n",
    "    p=quadgram_table[quad]\n",
    "    tri=quad[0:3]\n",
    "    token=quad[3]\n",
    "    quad_prob_table[tri][token]=p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score function to calculate the score of the model.\n",
    "+ For each correct prediction 1 is added to the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_score(quad_prob_table,test_quadgramSet):\n",
    "    score=0\n",
    "    print(len(test_quadgramSet))\n",
    "    for quad in test_quadgramSet:\n",
    "        tri=quad[0:3]\n",
    "        token=quad[3]\n",
    "        result=list(quad_prob_table[tri])\n",
    "        #print(result)\n",
    "        try:\n",
    "            if token==result[0]:\n",
    "                score+=1\n",
    "        except:\n",
    "            pass\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "5374\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: data sparsity\n",
    "+ We have insufficient data i.e there are many events x such that c(x) = 0, so that the ML estimate is $ P_{ML}(x) = 0$\n",
    "+ Whenever data sparsity is an issue, smoothing can help performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here will try out the following smoothings:\n",
    "+ Add-one\n",
    "+ Good Turing\n",
    "+ Kneser Ney\n",
    "+ Written Bell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-one smoothing:\n",
    "\n",
    "$$ P_{A1}(x|u,v,w)=\\frac{(C(u,v,w,x)+1)}{(|V|+C(u,v,w))}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now the quadgram table will contain probabilities of each quadgram\n",
    "for key in quadgram_table:\n",
    "    tri=key[0:3]\n",
    "    quadgram_table[key]=((quadgram_table[key]+1)/(trigram_table[tri]+V))\n",
    "                         \n",
    "quad_prob_table=defaultdict(dict)\n",
    "\n",
    "for quad in quadgram_table:\n",
    "    p=quadgram_table[quad]\n",
    "    tri=quad[0:3]\n",
    "    token=quad[3]\n",
    "    quad_prob_table[tri][token]=p\n",
    "    \n",
    "for quad in held_quadgramSet:\n",
    "    if quad not in quadgram_table:\n",
    "        quad_prob_table[quad[0:3]][quad[3]]=(1/(trigram_table[quad[0:3]]+V))\n",
    "        \n",
    "for tri in quad_prob_table:\n",
    "    x=sorted(quad_prob_table[tri].items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "5444\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0984005142933928\n"
     ]
    }
   ],
   "source": [
    "find_perplexity(quad_prob_table,test_quadgramSet,len(train_tokens))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two\n"
     ]
    }
   ],
   "source": [
    "#s=input(\"Enter a string:\")\n",
    "s=\"she is the youngest of the\"# a sentence in corpus. We need to find the next word for this sentence\n",
    "\n",
    "s=s.lower()\n",
    "s=preprocess(s)\n",
    "s_tokens=s.split()\n",
    "\n",
    "n=len(s_tokens)\n",
    "s_trigram=tuple(s_tokens[n-3:n])\n",
    "\n",
    "if s_trigram in quad_prob_table:\n",
    "    qword=list(quad_prob_table[(s_trigram)])\n",
    "    print((qword[0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing:\n",
    "+ $ N_c= $ Count of things we have seen c times\n",
    "+ $ P_{GT}^*$(things with zero frequency)$ = \\frac{N_1}{N} $\n",
    "+ $c^*=\\frac{(c+1)N_{c+1}}{N_c} $\n",
    "+ $ P_{GT}^* = \\frac{c^*}{N} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_table=[]\n",
    "quadgram_table=Counter(quadgrams)#stores the frequencies of each quadgram\n",
    "trigram_table=Counter(trigrams)\n",
    "#stores the frequencies of (counts of quadgrams)eg.N1=150 => no of quadgrams with count 1 are 150\n",
    "for quad in quadgram_table:\n",
    "    freq_table.append(quadgram_table[quad])\n",
    "    \n",
    "freq_table=Counter(freq_table)\n",
    "freq_table=dict(sorted(freq_table.items(), key=operator.itemgetter(0), reverse=True))\n",
    "\n",
    "N=len(quadgrams)\n",
    "N1=freq_table[1]\n",
    "N2=freq_table[2]\n",
    "D=N1/(N1+2*N2)\n",
    "\n",
    "for key in quadgram_table:\n",
    "    c=quadgram_table[key]\n",
    "    if c<=4:\n",
    "        Nc=freq_table[c]\n",
    "        Nd=freq_table[c+1]\n",
    "        quadgram_table[key]=(((c+1)*(Nd/Nc))/N)\n",
    "    else:\n",
    "        quadgram_table[key]=c-D\n",
    "                         \n",
    "quad_prob_table=defaultdict(dict)\n",
    "\n",
    "for quad in quadgram_table:\n",
    "    p=quadgram_table[quad]\n",
    "    tri=quad[0:3]\n",
    "    token=quad[3]\n",
    "    quad_prob_table[tri][token]=p   \n",
    "\n",
    "\n",
    "for quad in held_quadgramSet:\n",
    "    if quad not in quadgram_table:\n",
    "        #N=len(quad_prob_table[quad[0:3]])\n",
    "        quad_prob_table[quad[0:3]][quad[3]]=(N1/N)\n",
    "        \n",
    "for tri in quad_prob_table:\n",
    "    quad_prob_table[tri]=dict(sorted(quad_prob_table[tri].items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "6575\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'three']\n"
     ]
    }
   ],
   "source": [
    "#s=input(\"Enter a string:\")\n",
    "s=\"she is the youngest of the\"# a sentence in corpus. We need to find the next word for this sentence\n",
    "\n",
    "s=s.lower()\n",
    "s=preprocess(s)\n",
    "s_tokens=s.split()\n",
    "\n",
    "n=len(s_tokens)\n",
    "s_trigram=tuple(s_tokens[n-3:n])\n",
    "\n",
    "if s_trigram in quad_prob_table:\n",
    "    qword=list(quad_prob_table[(s_trigram)])\n",
    "    print((qword))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0805856545637793\n"
     ]
    }
   ],
   "source": [
    "find_perplexity(quad_prob_table,test_quadgramSet,len(train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing:\n",
    "+ Here we use $P_{continuation}$\n",
    "$$ P_{continuation}(w)=\\frac{|{w_{i-1}:C(w_{i-1},w)>0}|}{{|(w_{j-1},w_j):C(w_{j-1},w_j)>0}|}$$\n",
    "+ $P_{KN}$ is given as:\n",
    " $$P_{KN}(w_i|w_{i-1})= \\frac{max(c(w_{i-1},w_i)-d,0)}{c(w_{i-1})} + \\lambda(w_{i-1})P_{continuation}(w_i) $$\n",
    "+ $\\lambda$ is a normalizing constant given as:\n",
    "$$ \\lambda(w_{i-1})=\\frac{d}{c(w_{i-1})}|{w:c(w_{i-1},w)>0}|  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_table=[]\n",
    "quadgram_table=Counter(quadgrams)#stores the frequencies of each quadgram\n",
    "trigram_table=Counter(trigrams)\n",
    "#stores the frequencies of (counts of quadgrams)eg.N1=150 => no of quadgrams with count 1 are 150\n",
    "for quad in quadgram_table:\n",
    "    freq_table.append(quadgram_table[quad])\n",
    "    \n",
    "freq_table=Counter(freq_table)\n",
    "freq_table=dict(sorted(freq_table.items(), key=operator.itemgetter(0), reverse=True))\n",
    "#print(freq_table)\n",
    "\n",
    "#history_dict contains no. of different trigrams a token follows\n",
    "#future_dict contains no. different tokens a trigram follows\n",
    "history_dict=defaultdict(int)\n",
    "future_dict=defaultdict(int)\n",
    "for quad in quadgram_table:\n",
    "    token=quad[3]\n",
    "    history_dict[token]+=1\n",
    "    tri=quad[0:3]\n",
    "    future_dict[tri]+=1\n",
    "#this is to find Pcontinuation\n",
    "x=len(set(quadgrams))\n",
    "for quad in quadgram_table:\n",
    "    key=quad[3]\n",
    "    history_dict[key]=history_dict[key]/x\n",
    "#print(len(history_dict))\n",
    "\n",
    "    \n",
    "\n",
    "N=len(quadgrams)\n",
    "N1=freq_table[1]\n",
    "N2=freq_table[2]\n",
    "N3=freq_table[3]\n",
    "N4=freq_table[4]\n",
    "Y=N1/(N1+2*N2)\n",
    "D=[0]*4\n",
    "D[0]=Y\n",
    "D[1]=1-(2*Y*(N2/N1))\n",
    "D[2]=2-(3*Y*(N3/N2))\n",
    "D[3]=3-(4*Y*(N4/N3))\n",
    "\n",
    "for quad in quadgram_table:\n",
    "    c=quadgram_table[quad]\n",
    "    W=quad[3]\n",
    "    Wh=quad[0:3]\n",
    "    Pcont=history_dict[W]\n",
    "    if c<=3:\n",
    "        L=(D[c]/trigram_table[Wh])*future_dict[Wh]\n",
    "        Pkn=((max(c-D[c],0)/trigram_table[Wh])+(L*Pcont))\n",
    "    else:\n",
    "        L=(D[3]/trigram_table[Wh])*future_dict[Wh]\n",
    "        Pkn=((max(c-D[3],0)/trigram_table[Wh])+(L*Pcont))\n",
    "    quadgram_table[quad]=Pkn\n",
    "           \n",
    "quad_prob_table=defaultdict(dict)\n",
    "for quad in quadgram_table:\n",
    "    p=quadgram_table[quad]\n",
    "    tri=quad[0:3]\n",
    "    token=quad[3]\n",
    "    if p>0.0:\n",
    "        quad_prob_table[tri][token]=p   \n",
    "\n",
    "\n",
    "for quad in held_quadgramSet:\n",
    "    if quad not in quadgram_table:\n",
    "        c=quadgram_table[quad]\n",
    "        W=quad[3]\n",
    "        Wh=quad[0:3]\n",
    "        Pcont=history_dict[W]\n",
    "        if c<=3:\n",
    "            try:\n",
    "                L=(D[c]/trigram_table[Wh])*future_dict[Wh]\n",
    "                Pkn=((max(c-D[c],0)/trigram_table[Wh])+(L*Pcont))\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                L=(D[3]/trigram_table[Wh])*future_dict[Wh]\n",
    "                Pkn=((max(c-D[3],0)/trigram_table[Wh])+(L*Pcont)) \n",
    "            except:\n",
    "                pass\n",
    "        if Pkn>0.0:\n",
    "            quad_prob_table[quad[0:3]][quad[3]]=Pkn\n",
    "            #print(Pkn)\n",
    "        \n",
    "for tri in quad_prob_table:\n",
    "    quad_prob_table[tri]=dict(sorted(quad_prob_table[tri].items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "6795\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'three']\n"
     ]
    }
   ],
   "source": [
    "#s=input(\"Enter a string:\")\n",
    "s=\"she is the youngest of the\"# a sentence in corpus. We need to find the next word for this sentence\n",
    "\n",
    "s=s.lower()\n",
    "s=preprocess(s)\n",
    "s_tokens=s.split()\n",
    "\n",
    "n=len(s_tokens)\n",
    "s_trigram=tuple(s_tokens[n-3:n])\n",
    "\n",
    "if s_trigram in quad_prob_table:\n",
    "    qword=list(quad_prob_table[(s_trigram)])\n",
    "    print((qword))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.022051514888769\n"
     ]
    }
   ],
   "source": [
    "find_perplexity(quad_prob_table,test_quadgramSet,len(train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written-Bell smoothing:\n",
    "$ P_{WB}(x|u,v,w)=\\frac{(C_h(u,v,w)}{C_h(u,v,w)+N_{1+(u,v,w)}}P_{MLE}(x|u,v,w) + \\frac{N_{1+u,v,w}}{Ch(u,v,w)+N_{1+u,v,w}}P_{BO}(u,v,w) $\n",
    "\n",
    "$ P_{BO}(u,v,w)=\\frac{C_h(\\epsilon)}{C_h(\\epsilon)+N_{1+\\epsilon}}P_{MLE}(u,v,w)+\\frac{N_{1+\\epsilon}}{C_h(\\epsilon)+N_{1+\\epsilon}}\\frac{1}{|V|}  $\n",
    "\n",
    "- $ C_h(w)$ is the total words following w.\n",
    "- $N_{1+w}$ is number of word types following w\n",
    "- The term $C_h(\\epsilon)$ is the 0-gram history count.\n",
    "- $N_{1+\\epsilon}$ is the number of different words with at least one count.\n",
    "- For the backoff distribution for the unigram model, we use the uniform distribution $P_{unif}(w_i) = \\frac{1}{|V|}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_table=Counter(train_tokens)\n",
    "trigram_table=Counter(trigrams)\n",
    "bigram_table=Counter(bigrams)\n",
    "quadgram_table=Counter(quadgrams)\n",
    "Chw=defaultdict(int)\n",
    "for quad in quadgrams:\n",
    "    Chw[quad[0:3]]+=1\n",
    "Nw=defaultdict(int)\n",
    "for quad in quadgram_table:\n",
    "    Nw[quad[0:3]]+=1\n",
    "n=len(train_tokens)\n",
    "Ceps=len(train_tokens)\n",
    "Neps=len(set(train_tokens))\n",
    "V=len(quadgram_table)\n",
    "quad_prob_table=defaultdict(dict)\n",
    "for quad in quadgram_table:\n",
    "    Pbo=((Ceps/(Ceps+Neps))*(unigram_table[quad[3]]/n))+(Neps/(Ceps+Neps)*V)\n",
    "    P=((Chw[quad[0:3]]/(Chw[quad[0:3]]+Nw[quad[0:3]]))*(quadgram_table[quad]/trigram_table[quad[0:3]]))\n",
    "    quad_prob_table[quad[0:3]][quad[3]]=P+((Nw[quad[0:3]]/(Chw[quad[0:3]]+Nw[quad[0:3]]))*Pbo)\n",
    "for quad in held_quadgramSet:\n",
    "    if quad not in quadgram_table:\n",
    "        Pbo=((Ceps/(Ceps+Neps))*(unigram_table[quad[3]]/n))+(Neps/(Ceps+Neps)*V)\n",
    "        try:\n",
    "            Pwb=((Chw[quad[0:3]]/(Chw[quad[0:3]]+Nw[quad[0:3]]))*(quadgram_table[quad]/trigram_table[quad[0:3]]))+((Nw[quad[0:3]]/(Chw[quad[0:3]]+Nw[quad[0:3]]))*Pbo)\n",
    "        except:\n",
    "            Pwb=0\n",
    "        if Pwb>0:\n",
    "            quad_prob_table[quad[0:3]][quad[3]]=Pwb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "5374\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388966644498519\n"
     ]
    }
   ],
   "source": [
    "find_perplexity(quad_prob_table,test_quadgramSet,len(train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interpolation\n",
    "- Mix  unigram,  bigram,  trigram and so on\n",
    "\n",
    "$$ P(w_n|w_{n-3},w_{n-2},w_{n-1}) = \\lambda_1 P(w_n|w_{n-3},w_{n-2},w_{n-1}) + \\lambda_2 P(w_n|w_{n-2},w_{n-1}) + \\lambda_3 P(w_n|w_{n-1}) + \\lambda_4 P(w_n)   $$\n",
    "- Find out the values of lambdas that gives the best results on held-out set\n",
    "\n",
    "$  M(\\lambda_1,\\lambda_2,\\lambda_3,\\lambda_4) = \\sum_{u,v,w,x}log q(x|u,v,w) $\n",
    "                                           $  = \\sum_{u,v,w,x}log(\\lambda_1 × qML(x|u,v,w) + \\lambda_2 × qML(x|v,w) + \\lambda_3 × qML(x|w) + \\lambda_4 x qML(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "probList=[]\n",
    "count=[]\n",
    "\n",
    "Hunigrams=list(ngrams(held_tokens,1))\n",
    "Hbigrams=list(ngrams(held_tokens,2))\n",
    "Htrigrams=list(ngrams(held_tokens,3))\n",
    "Hquadgrams=list(ngrams(held_tokens,4))\n",
    "print(len(set(Hquadgrams)))\n",
    "\n",
    "Hquadgram_table=Counter(Hquadgrams)\n",
    "Htrigram_table=Counter(Htrigrams)\n",
    "Hbigram_table=Counter(Hbigrams)\n",
    "Hunigram_table=Counter(held_tokens)\n",
    "n=len(Hunigram_table)\n",
    "for quad in Hquadgram_table:\n",
    "    tri=quad[1:4]\n",
    "    bi=quad[2:4]\n",
    "    uni=quad[3]\n",
    "    l=[(Hquadgram_table[quad]/Htrigram_table[quad[0:3]]),(Htrigram_table[tri]/Hbigram_table[quad[1:3]]),(Hbigram_table[bi]/Hunigram_table[quad[2]]),(Hunigram_table[uni]/n)]\n",
    "    probList.append(l)\n",
    "    count.append(Hquadgram_table[quad])\n",
    "\n",
    "probList=np.array(probList)\n",
    "#print((probList))\n",
    "count=np.array(count)\n",
    "#print(count[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# now = datetime.datetime.now()\n",
    "# print(str(now))\n",
    "import itertools\n",
    "import numpy as np\n",
    "from math import log10\n",
    "x_dim=np.arange(0.01, 0.99, 0.01)\n",
    "y_dim=np.arange(0.01, 0.99, 0.01)\n",
    "z_dim=np.arange(0.01, 0.99, 0.01)\n",
    "l=[]\n",
    "for w, x, y in itertools.product(x_dim, y_dim, z_dim):\n",
    "    s=w+x+y\n",
    "    if s<1:\n",
    "        z=1-s\n",
    "        l.append([w,x,y,z])\n",
    "# print(str(now))\n",
    "# print(len(l))\n",
    "L=[]\n",
    "I=[]\n",
    "maxL=float('-inf')\n",
    "maxI=defaultdict(dict)\n",
    "i=0\n",
    "for item in l:\n",
    "    #print(i)\n",
    "    i+=1\n",
    "    new_pList=probList*item\n",
    "    L.append((np.sum(np.log10((np.sum(new_pList, axis=1))))))\n",
    "    I.append(item)\n",
    "    \n",
    "k=0\n",
    "for item in L:\n",
    "    maxI[item]=I[k]\n",
    "    k+=1\n",
    "\n",
    "maxI=sorted(maxI.items(), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(maxI[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#params=maxI[0][1]\n",
    "params=[0.96999999999999997, 0.01, 0.01, 0.010000000000000009]\n",
    "#maxI=[0.25,0.25,0.25,0.25]\n",
    "unigrams=list(ngrams(train_tokens,1))\n",
    "bigrams=list(ngrams(train_tokens,2))\n",
    "trigrams=list(ngrams(train_tokens,3))\n",
    "quadgrams=list(ngrams(train_tokens,4))\n",
    "\n",
    "quadgram_table=Counter(quadgrams)#stores the frequencies of each quadgram\n",
    "trigram_table=Counter(trigrams)\n",
    "bigram_table=Counter(bigrams)\n",
    "unigram_table=Counter(train_tokens)\n",
    "\n",
    "t_words=defaultdict(dict)\n",
    "b_words=defaultdict(dict)\n",
    "for tri in trigram_table:\n",
    "    bi=tri[0:2]\n",
    "    t_words[bi][tri[2]]=trigram_table[tri]/bigram_table[bi]\n",
    "for bi in t_words:\n",
    "    t_words[bi]=dict(sorted(t_words[bi].items(), key=lambda x: x[1], reverse=True)[0:20])\n",
    "\n",
    "\n",
    "for bi in bigram_table:\n",
    "    uni=bi[0]\n",
    "    b_words[uni][bi[1]]=bigram_table[bi]/unigram_table[uni]\n",
    "for uni in b_words:\n",
    "    b_words[uni]=dict((sorted(b_words[uni].items(), key=lambda x: x[1], reverse=True))[0:20])\n",
    "n=len(unigram_table)\n",
    "i=0\n",
    "for tri in quad_prob_table:\n",
    "#     print(i)\n",
    "#     i+=1\n",
    "#     if i>20:\n",
    "#         break\n",
    "    bi=tri[1:3]\n",
    "    new_words=t_words[bi]\n",
    "    quad_prob_table[tri].update(new_words)\n",
    "    \n",
    "    uni=tri[2]\n",
    "    new_words=b_words[uni]\n",
    "    quad_prob_table[tri].update(new_words)\n",
    "   \n",
    "\n",
    "    for key in quad_prob_table[tri]:\n",
    "        #print(quad_prob_table[tri])\n",
    "        quadgram=tri+(key,)\n",
    "        trigram=tri[1:3]+(key,)\n",
    "        bigram=(tri[2],)+(key,)\n",
    "        #print(quadgram,trigram,bigram)\n",
    "        try:\n",
    "            qML1=params[0]*(quadgram_table[quadgram]/trigram_table[quadgram[0:3]])\n",
    "        except:\n",
    "            qML1=0\n",
    "        try:\n",
    "            qML2=params[1]*(trigram_table[trigram]/bigram_table[trigram[0:2]])\n",
    "        except:\n",
    "            qML2=0\n",
    "        try:\n",
    "            qML3=params[2]*(bigram_table[bigram]/unigram_table[bigram[0]])\n",
    "        except:\n",
    "            qML3=0\n",
    "        try:\n",
    "            qML4=params[3]*(unigram_table[key]/n)\n",
    "        except:\n",
    "            qML4=0\n",
    "        quad_prob_table[tri][key]=qML1+qML2+qML3+qML4\n",
    "        #print(type(quad_prob_table[tri]))\n",
    "\n",
    "    quad_prob_table[tri]=dict(sorted(quad_prob_table[tri].items(), key=lambda x: x[1], reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "7136\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0378421891734135"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_perplexity(quad_prob_table,test_quadgramSet,len(train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backoff\n",
    "- In Back off we use the quadgram if the evidence is sufficient, other wise we use the trigram otherwise bigram amd so on.\n",
    "- That means we back-off to a lower order N-gram if we have zero or insufficient evidence for a higher order Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "Qfreq_table=[]\n",
    "Tfreq_table=[]\n",
    "Bfreq_table=[]\n",
    "quadgram_table=Counter(quadgrams)#stores the frequencies of each quadgram\n",
    "trigram_table=Counter(trigrams)\n",
    "bigram_table=Counter(bigrams)\n",
    "#stores the frequencies of (counts of quadgrams)eg.N1=150 => no of quadgrams with count 1 are 150\n",
    "for quad in quadgram_table:\n",
    "    Qfreq_table.append(quadgram_table[quad])\n",
    "for tri in trigram_table:\n",
    "    Tfreq_table.append(trigram_table[tri])\n",
    "for bi in bigram_table:\n",
    "    Bfreq_table.append(bigram_table[bi])\n",
    "    \n",
    "Qfreq_table=Counter(Qfreq_table)\n",
    "Qf=[]\n",
    "for c in Qfreq_table:\n",
    "    Qf.append(c)\n",
    "Tfreq_table=Counter(Tfreq_table)\n",
    "Tf=[]\n",
    "for c in Tfreq_table:\n",
    "    Tf.append(c)\n",
    "Bfreq_table=Counter(Bfreq_table)\n",
    "Bf=[]\n",
    "for c in Bfreq_table:\n",
    "    Bf.append(c)\n",
    "Qf=sorted(Qf)[0:10]\n",
    "Tf=sorted(Tf)[0:10]\n",
    "Bf=sorted(Bf)[0:10]\n",
    "print(len(Qf)*len(Tf)*len(Bf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103665\n",
      "189646.265347 [10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "probList=[]\n",
    "\n",
    "Hunigrams=list(ngrams(held_tokens,1))\n",
    "Hbigrams=list(ngrams(held_tokens,2))\n",
    "Htrigrams=list(ngrams(held_tokens,3))\n",
    "Hquadgrams=list(ngrams(held_tokens,4))\n",
    "print(len(set(Hquadgrams)))\n",
    "\n",
    "Hquadgram_table=Counter(Hquadgrams)#stores the frequencies of each quadgram\n",
    "Htrigram_table=Counter(Htrigrams)\n",
    "Hbigram_table=Counter(Hbigrams)\n",
    "Hunigram_table=Counter(held_tokens)\n",
    "#n=len(Hunigram_table)\n",
    "for quad in Hquadgram_table:\n",
    "    tri=quad[1:4]\n",
    "    bi=quad[2:4]\n",
    "    uni=quad[3]\n",
    "    l=[(Hquadgram_table[quad]),(Htrigram_table[tri]),(Hbigram_table[bi]),(Hunigram_table[uni])]\n",
    "    probList.append(l)\n",
    "    #count.append(Hquadgram_table[quad])\n",
    "\n",
    "probList=np.array(probList)\n",
    "\n",
    "cnts=[]\n",
    "results=defaultdict(dict)\n",
    "r=[]\n",
    "cs=[]\n",
    "p=1\n",
    "maxP=0\n",
    "maxC=[]\n",
    "\n",
    "for c1 in Qf:\n",
    "    for c2 in Tf:\n",
    "        for c3 in Bf:\n",
    "            cnts.append([c1,c2,c3])\n",
    "#print(cnts)\n",
    "i=0\n",
    "for c in cnts:\n",
    "#     print(c)\n",
    "#     if i>10:\n",
    "#         break\n",
    "#     print(i)\n",
    "    i+=1\n",
    "    t=[]\n",
    "    for probs in probList:\n",
    "        if probs[0]>c[0]:\n",
    "            t.append(probs[0])\n",
    "        elif probs[1]>c[1]:\n",
    "            t.append(probs[1])\n",
    "        elif probs[2]>c[2]:\n",
    "            t.append(probs[2])\n",
    "        else:\n",
    "            t.append(probs[3])\n",
    "    #print(t,\"\\n\\n\\n\\n\")\n",
    "    t=np.array(t)\n",
    "    p=np.sum(np.log10(t))\n",
    "    r.append(p)\n",
    "    cs.append(c)\n",
    "    if p>maxP:\n",
    "        maxP=p\n",
    "        maxC=c\n",
    "    \n",
    "print(maxP,maxC)    \n",
    "k=0\n",
    "for p in r:\n",
    "    results[p]=cs[k]\n",
    "    k+=1\n",
    "\n",
    "results=(sorted(results.items(), key=lambda x: x[0], reverse=True))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "#print(results[0:10])\n",
    "quad_prob_table=defaultdict(dict)\n",
    "val=results[0][1]\n",
    "print(val)\n",
    "for quad in quadgram_table:\n",
    "    qc=quadgram_table[quad]\n",
    "    tc=trigram_table[quad[1:4]]\n",
    "    bc=bigram_table[quad[2:4]]\n",
    "    uc=unigram_table[quad[3]]\n",
    "    if qc>c[0]:\n",
    "        p=qc\n",
    "    elif tc>c[1]:\n",
    "        p=tc\n",
    "    elif bc>c[2]:\n",
    "        p=bc\n",
    "    else:\n",
    "        p=uc\n",
    "    quad_prob_table[quad[0:3]][quad[3]]=p\n",
    "\n",
    "for tri in quad_prob_table:\n",
    "    quad_prob_table[tri]=dict(sorted(quad_prob_table[tri].items(),key=lambda x: x[1],reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102982\n",
      "4611\n"
     ]
    }
   ],
   "source": [
    "find_score(quad_prob_table,test_quadgramSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "+ https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf\n",
    "+ https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
