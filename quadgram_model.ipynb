{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of next word of a sentence using Quadgram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Read the corpus file line by line\n",
    "### 2)Preprocess the content of the file:\n",
    "       (i) Lower case all the words\n",
    "       (ii) Remove puntuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053640\n",
      "62705\n"
     ]
    }
   ],
   "source": [
    "tokens=[]\n",
    "#with open('/home/meghana/new_jupyter/assign1/Data/Tokenization/Chat1.txt') as f:\n",
    "with open('/home/meghana/nltk_data/corpora/gutenberg/corpusfile.txt') as f:\n",
    "\n",
    "    for line in f:\n",
    "        if not line.isspace():\n",
    "            items=line.split()\n",
    "            #print(\"words in list;\",items)\n",
    "            i=0\n",
    "            for w in items:\n",
    "                items[i]=w.lower()\n",
    "                items[i]=items[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace(\"'\",'')                                 \n",
    "                i+=1\n",
    "            tokens+=items\n",
    "tokenSet=set(tokens)\n",
    "print(len(tokens))\n",
    "print(len(tokenSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtered_words=[word for word in tokens if word not in stopwords.words('english')]\n",
    "# #filtered_words_set=set(filtered_words)\n",
    "# print(len(filtered_words))\n",
    "# print(len(filtered_words_set))\n",
    "# tokens=filtered_words\n",
    "# tokenSet=set(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the words of the files as ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421195\n",
      "1826910\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "unigrams=list(ngrams(tokens,1))\n",
    "trigrams=list(ngrams(tokens,3))\n",
    "trigramSet=set(trigrams)\n",
    "quadgrams=list(ngrams(tokens,4))\n",
    "quadgramSet=set(quadgrams)\n",
    "print(len(trigramSet))\n",
    "print(len(quadgramSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct the probability tables of quadgrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from collections import Counter\n",
    "\n",
    "unigram_table=Counter(unigrams)\n",
    "default=(unigram_table.most_common(1))\n",
    "default=str(default[0][0])\n",
    "default=default.replace('(','').replace(\"'\",'').replace(',','').replace(')','')\n",
    "#print(default)\n",
    "\n",
    "trigram_list=[]\n",
    "for item in trigrams:\n",
    "    new_item=' '.join(item)\n",
    "    trigram_list.append(new_item)\n",
    "\n",
    "trigram_table=Counter(trigram_list)   \n",
    "#print(trigram_table.most_common(10))\n",
    "\n",
    "\n",
    "quadgram_list=[]\n",
    "for item in quadgrams:\n",
    "    new_item=' '.join(item)\n",
    "    quadgram_list.append(new_item)\n",
    "\n",
    "quadgram_table=Counter(quadgram_list)   \n",
    "#print(quadgram_table.most_common(10))\n",
    "#print(quadgram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Look up the quadgram and trigram tables \n",
    "### 2)Take the input string\n",
    "### 3)Find out the probability and predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a string:I am Meghana Bandaru and I must\n",
      "The next word is: say\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "#s=\"I am Meghana Bandaru and I must\"\n",
    "s=input(\"Enter a string:\")\n",
    "s_tokens=s.split()\n",
    "#s_filtered_words=[word for word in s_tokens if word not in stopwords.words('english')]\n",
    "#s_tokens=s_filtered_words\n",
    "i=0\n",
    "for w in s_tokens:\n",
    "    s_tokens[i]=w.lower()\n",
    "    s_tokens[i]=s_tokens[i].replace('.','').replace(',','').replace(':','').replace(';','').replace('!','').replace('?','').replace('(','').replace(')','').replace(\"'\",'')                                 \n",
    "    i+=1\n",
    "\n",
    "s_trigrams=list(ngrams(s_tokens, 3))\n",
    "#print(s_trigrams)\n",
    "n=len(s_trigrams)\n",
    "req_trigram=s_trigrams[n-1]\n",
    "req_trigram=' '.join(req_trigram)\n",
    "#print(req_trigram)\n",
    "\n",
    "prob=0\n",
    "freq_tri=0\n",
    "freq_quad=0\n",
    "max_prob=0\n",
    "result=0\n",
    "word=0\n",
    "for item in tokenSet:\n",
    "    new_req_trigram=req_trigram+' '+item\n",
    "    freq_quad=quadgram_table[new_req_trigram]\n",
    "    freq_tri=trigram_table[req_trigram]\n",
    "    if(freq_tri==0):\n",
    "        break\n",
    "    prob=freq_quad/freq_tri\n",
    "    if(prob>max_prob):\n",
    "        max_prob=prob\n",
    "        result=new_req_trigram\n",
    "        word=item\n",
    "if(word==0):\n",
    "    word=default\n",
    "    result=req_trigram+' '+str(default)\n",
    "    \n",
    "print(\"The next word is:\", word)\n",
    "#print(\"The sentence might be:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
